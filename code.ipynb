{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "I603-UmCQaC7",
        "outputId": "0fe3b136-31e9-4cbb-f178-aa1a3464e147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.43.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.6.1)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (6.2.4)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.359.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.11.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Downloading pennylane-0.43.2-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.359.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.0 diastatic-malt-2.15.2 pennylane-0.43.2 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.359.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane scikit-learn matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "0Y-XTKWaQqdp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data"
      ],
      "metadata": {
        "id": "69OK4UcRQ5C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data(n_samples=200, test_size=0.3, noise=0.1):\n",
        "    X, y = make_moons(\n",
        "        n_samples=n_samples,\n",
        "        noise=noise,\n",
        "        random_state=42\n",
        "    )\n",
        "    y = 2 * y - 1   # {0,1} -> {-1, +1}\n",
        "    return train_test_split(X, y, test_size=test_size, random_state=42)\n"
      ],
      "metadata": {
        "id": "OhK6cpXsQ6np"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "pHl1YvIiRDKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_qubits = 3\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(x, weights):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RX(x[0], wires=i)\n",
        "        qml.RY(x[1], wires=i)\n",
        "        qml.RY(weights[i], wires=i)\n",
        "\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "\n",
        "    # Measure Z^{\\otimes n}\n",
        "    return qml.expval(\n",
        "        qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2)\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "9CqSSEkiQ9c6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "fuRbgXRnRMKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "\n",
        "def mse_loss(weights, X, y):\n",
        "    \"\"\"\n",
        "    Mean Squared Error (MSE) loss for the PQC classifier.\n",
        "    \"\"\"\n",
        "    loss = 0.0\n",
        "    for xi, yi in zip(X, y):\n",
        "        pred = quantum_circuit(xi, weights)\n",
        "        loss += (pred - yi) ** 2\n",
        "    return loss / len(X)\n",
        "\n",
        "def train_model(X_train, y_train, epochs=30, lr=0.02):\n",
        "    \"\"\"\n",
        "    Train the parameterized quantum circuit using a hybrid\n",
        "    quantum–classical optimization loop.\n",
        "    \"\"\"\n",
        "    weights = np.random.randn(n_qubits)\n",
        "    opt = qml.AdamOptimizer(lr)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        weights, loss = opt.step_and_cost(\n",
        "            lambda w: mse_loss(w, X_train, y_train),\n",
        "            weights\n",
        "        )\n",
        "        losses.append(loss)\n",
        "\n",
        "        print(\n",
        "            f\"[Training] Epoch {epoch:02d} | \"\n",
        "            f\"MSE loss on training set = {loss:.4f}\"\n",
        "        )\n",
        "\n",
        "    return weights, losses\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1jn-u2ifRGAY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize"
      ],
      "metadata": {
        "id": "op7DOjNQRPO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(losses):\n",
        "    \"\"\"\n",
        "    Plot the training loss (MSE) of the PQC classifier.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.plot(losses, marker='o')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss (MSE)\")\n",
        "    plt.title(\"Training loss (MSE) of the PQC classifier\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8eyV8yi4RT-y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big/small"
      ],
      "metadata": {
        "id": "qdu2lF0ERYG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_big = qml.device(\"default.qubit\", wires=6)\n",
        "dev_small = qml.device(\"default.qubit\", wires=3)\n",
        "\n",
        "@qml.qnode(dev_big)\n",
        "def big_circuit(x, weights):\n",
        "    for i in range(6):\n",
        "        qml.RX(x[0], wires=i)\n",
        "        qml.RY(x[1], wires=i)\n",
        "        qml.RY(weights[i], wires=i)\n",
        "\n",
        "    for i in range(5):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "\n",
        "    # Measure Z^{\\otimes 6}\n",
        "    return qml.expval(\n",
        "        qml.PauliZ(0)\n",
        "        @ qml.PauliZ(1)\n",
        "        @ qml.PauliZ(2)\n",
        "        @ qml.PauliZ(3)\n",
        "        @ qml.PauliZ(4)\n",
        "        @ qml.PauliZ(5)\n",
        "    )\n",
        "\n",
        "@qml.qnode(dev_small)\n",
        "def small_circuit(x, weights):\n",
        "    for i in range(3):\n",
        "        qml.RX(x[0], wires=i)\n",
        "        qml.RY(x[1], wires=i)\n",
        "        qml.RY(weights[i], wires=i)\n",
        "\n",
        "    for i in range(2):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "\n",
        "    # Measure Z^{\\otimes 3}\n",
        "    return qml.expval(\n",
        "        qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "ykHbe8bVRWDM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "ehrbWZCfRcZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# Load data\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = load_data()\n",
        "\n",
        "# -----------------------------\n",
        "# Repeated runs with different seeds\n",
        "# -----------------------------\n",
        "seeds = [0, 1, 2, 3, 4]\n",
        "accuracies = []\n",
        "\n",
        "for i, seed in enumerate(seeds):\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(f\"Run {i+1}/{len(seeds)} with random seed = {seed}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Train PQC classifier\n",
        "    weights, losses = train_model(X_train, y_train)\n",
        "\n",
        "    # Plot loss only once\n",
        "    if i == 0:\n",
        "        plot_loss(losses)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    correct = 0\n",
        "    for x, y in zip(X_test, y_test):\n",
        "        pred = quantum_circuit(x, weights)\n",
        "        if np.sign(pred) == y:\n",
        "            correct += 1\n",
        "\n",
        "    acc = correct / len(y_test)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    print(f\"[Evaluation] Test accuracy: {acc:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Cross-validation summary\n",
        "# -----------------------------\n",
        "mean_acc = np.mean(accuracies)\n",
        "std_acc = np.std(accuracies)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Cross-validation results for PQC classifier\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Average test accuracy: {mean_acc:.3f}\")\n",
        "print(f\"Standard deviation:   {std_acc:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Big → Small approximation\n",
        "# -----------------------------\n",
        "np.random.seed(0)\n",
        "big_weights = np.random.randn(6)\n",
        "\n",
        "M = 4\n",
        "small_weights_list = [np.random.randn(3) for _ in range(M)]\n",
        "\n",
        "errors = []\n",
        "\n",
        "for x in X_test:\n",
        "    f_big = big_circuit(x, big_weights)\n",
        "    f_small_hat = np.mean(\n",
        "        [small_circuit(x, w) for w in small_weights_list]\n",
        "    )\n",
        "    errors.append((f_big - f_small_hat) ** 2)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Approximation of a large circuit using small circuits\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Number of small circuits (M): {M}\")\n",
        "print(f\"MSE (big → small): {np.mean(errors):.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uqdYN50pRdPb",
        "outputId": "baf49fb6-4be1-48ee-90a5-d5a44ec97e81"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------\n",
            "Run 1/5 with random seed = 0\n",
            "----------------------------------------\n",
            "[Training] Epoch 00 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 01 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 02 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 03 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 04 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 05 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 06 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 07 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 08 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 09 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 10 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 11 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 12 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 13 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 14 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 15 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 16 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 17 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 18 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 19 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 20 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 21 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 22 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 23 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 24 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 25 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 26 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 27 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 28 | MSE loss on training set = 1.1048\n",
            "[Training] Epoch 29 | MSE loss on training set = 1.1048\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Evaluation] Test accuracy: 0.333\n",
            "\n",
            "----------------------------------------\n",
            "Run 2/5 with random seed = 1\n",
            "----------------------------------------\n",
            "[Training] Epoch 00 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 01 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 02 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 03 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 04 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 05 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 06 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 07 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 08 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 09 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 10 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 11 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 12 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 13 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 14 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 15 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 16 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 17 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 18 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 19 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 20 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 21 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 22 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 23 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 24 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 25 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 26 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 27 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 28 | MSE loss on training set = 0.7659\n",
            "[Training] Epoch 29 | MSE loss on training set = 0.7659\n",
            "[Evaluation] Test accuracy: 0.767\n",
            "\n",
            "----------------------------------------\n",
            "Run 3/5 with random seed = 2\n",
            "----------------------------------------\n",
            "[Training] Epoch 00 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 01 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 02 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 03 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 04 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 05 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 06 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 07 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 08 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 09 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 10 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 11 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 12 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 13 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 14 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 15 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 16 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 17 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 18 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 19 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 20 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 21 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 22 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 23 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 24 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 25 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 26 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 27 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 28 | MSE loss on training set = 1.3398\n",
            "[Training] Epoch 29 | MSE loss on training set = 1.3398\n",
            "[Evaluation] Test accuracy: 0.167\n",
            "\n",
            "----------------------------------------\n",
            "Run 4/5 with random seed = 3\n",
            "----------------------------------------\n",
            "[Training] Epoch 00 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 01 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 02 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 03 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 04 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 05 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 06 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 07 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 08 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 09 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 10 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 11 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 12 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 13 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 14 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 15 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 16 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 17 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 18 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 19 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 20 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 21 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 22 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 23 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 24 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 25 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 26 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 27 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 28 | MSE loss on training set = 0.8514\n",
            "[Training] Epoch 29 | MSE loss on training set = 0.8514\n",
            "[Evaluation] Test accuracy: 0.700\n",
            "\n",
            "----------------------------------------\n",
            "Run 5/5 with random seed = 4\n",
            "----------------------------------------\n",
            "[Training] Epoch 00 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 01 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 02 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 03 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 04 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 05 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 06 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 07 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 08 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 09 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 10 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 11 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 12 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 13 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 14 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 15 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 16 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 17 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 18 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 19 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 20 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 21 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 22 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 23 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 24 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 25 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 26 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 27 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 28 | MSE loss on training set = 1.2524\n",
            "[Training] Epoch 29 | MSE loss on training set = 1.2524\n",
            "[Evaluation] Test accuracy: 0.467\n",
            "\n",
            "==================================================\n",
            "Cross-validation results for PQC classifier\n",
            "==================================================\n",
            "Average test accuracy: 0.487\n",
            "Standard deviation:   0.224\n",
            "\n",
            "==================================================\n",
            "Approximation of a large circuit using small circuits\n",
            "==================================================\n",
            "Number of small circuits (M): 4\n",
            "MSE (big → small): 0.1393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Experiment: Effect of M under different aggregation strategies\")\n",
        "print(\"Seed fixed to 0 (fully aligned with Big→Small baseline)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "M_values = [1, 2, 4, 8, 16]\n",
        "\n",
        "for M in M_values:\n",
        "    np.random.seed(0)   #\n",
        "\n",
        "    big_weights = np.random.randn(6)\n",
        "    small_weights_list = [np.random.randn(3) for _ in range(M)]\n",
        "\n",
        "    w = np.random.rand(M)\n",
        "    w = w / np.sum(w)\n",
        "\n",
        "    errors_mean = []\n",
        "    errors_weighted = []\n",
        "\n",
        "    for x in X_test:\n",
        "        f_big = big_circuit(x, big_weights)\n",
        "        f_smalls = np.array([small_circuit(x, w_i) for w_i in small_weights_list])\n",
        "\n",
        "        f_mean = np.mean(f_smalls)\n",
        "        f_weighted = np.dot(w, f_smalls)\n",
        "\n",
        "        errors_mean.append((f_big - f_mean) ** 2)\n",
        "        errors_weighted.append((f_big - f_weighted) ** 2)\n",
        "\n",
        "    print(\n",
        "        f\"M = {M:2d} | \"\n",
        "        f\"Mean MSE = {np.mean(errors_mean):.4f} | \"\n",
        "        f\"Weighted Mean MSE = {np.mean(errors_weighted):.4f}\"\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks2xQk1rodLo",
        "outputId": "a6b4f853-ef63-45b6-8563-62fd55978372"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Experiment: Effect of M under different aggregation strategies\n",
            "Seed fixed to 0 (fully aligned with Big→Small baseline)\n",
            "======================================================================\n",
            "M =  1 | Mean MSE = 0.1307 | Weighted Mean MSE = 0.1307\n",
            "M =  2 | Mean MSE = 0.0718 | Weighted Mean MSE = 0.0607\n",
            "M =  4 | Mean MSE = 0.1393 | Weighted Mean MSE = 0.1629\n",
            "M =  8 | Mean MSE = 0.0476 | Weighted Mean MSE = 0.0297\n",
            "M = 16 | Mean MSE = 0.0796 | Weighted Mean MSE = 0.0492\n"
          ]
        }
      ]
    }
  ]
}